{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.398520</td>\n",
       "      <td>2.499091</td>\n",
       "      <td>0.178797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.403833</td>\n",
       "      <td>2.489971</td>\n",
       "      <td>0.105971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.451285</td>\n",
       "      <td>2.485884</td>\n",
       "      <td>0.033656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.515515</td>\n",
       "      <td>2.479439</td>\n",
       "      <td>-0.027975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.560541</td>\n",
       "      <td>2.492715</td>\n",
       "      <td>-0.047035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>0.962859</td>\n",
       "      <td>-2.179569</td>\n",
       "      <td>-2.287310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>0.938350</td>\n",
       "      <td>-2.179777</td>\n",
       "      <td>-2.362097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>0.894981</td>\n",
       "      <td>-2.185274</td>\n",
       "      <td>-2.387264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>0.858602</td>\n",
       "      <td>-2.230196</td>\n",
       "      <td>-2.407852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>0.831630</td>\n",
       "      <td>-2.309509</td>\n",
       "      <td>-2.459917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13857 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -3.398520  2.499091  0.178797\n",
       "1     -3.403833  2.489971  0.105971\n",
       "2     -3.451285  2.485884  0.033656\n",
       "3     -3.515515  2.479439 -0.027975\n",
       "4     -3.560541  2.492715 -0.047035\n",
       "...         ...       ...       ...\n",
       "13852  0.962859 -2.179569 -2.287310\n",
       "13853  0.938350 -2.179777 -2.362097\n",
       "13854  0.894981 -2.185274 -2.387264\n",
       "13855  0.858602 -2.230196 -2.407852\n",
       "13856  0.831630 -2.309509 -2.459917\n",
       "\n",
       "[13857 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import treated data\n",
    "\n",
    "xlsx = pd.ExcelFile('Feature_extracts well1.xlsx')\n",
    "df = pd.read_excel(xlsx, 'PCAs')\n",
    "dataset_pca= df.copy()\n",
    "\n",
    "\n",
    "\n",
    "dataset_pca.pop('index')\n",
    "\n",
    "# dataset_pca1= dataset_pca('PC1','PC1','PC3')\n",
    "dataset_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RHOB</th>\n",
       "      <th>RHOB_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.520406</td>\n",
       "      <td>2.24710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.418822</td>\n",
       "      <td>2.25870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.417071</td>\n",
       "      <td>2.25890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.454727</td>\n",
       "      <td>2.25460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.481874</td>\n",
       "      <td>2.25150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>0.924172</td>\n",
       "      <td>2.52625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>0.921107</td>\n",
       "      <td>2.52590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>0.918042</td>\n",
       "      <td>2.52555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>0.914977</td>\n",
       "      <td>2.52520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>0.984159</td>\n",
       "      <td>2.53310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13857 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RHOB   RHOB_r\n",
       "0     -1.520406  2.24710\n",
       "1     -1.418822  2.25870\n",
       "2     -1.417071  2.25890\n",
       "3     -1.454727  2.25460\n",
       "4     -1.481874  2.25150\n",
       "...         ...      ...\n",
       "13852  0.924172  2.52625\n",
       "13853  0.921107  2.52590\n",
       "13854  0.918042  2.52555\n",
       "13855  0.914977  2.52520\n",
       "13856  0.984159  2.53310\n",
       "\n",
       "[13857 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import treated data\n",
    "\n",
    "# xlsx_3 = pd.ExcelFile('Feature_extracts.xlsx')\n",
    "df_2 = pd.read_excel(xlsx, 'target')\n",
    "pca_target= df_2.copy()\n",
    "\n",
    "pca_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 9699\n",
      "test samples 4158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "train_input, test_input, train_target, test_target = model_selection.train_test_split(dataset_pca, pca_target['RHOB_r'], train_size=0.7)\n",
    "\n",
    "print('train samples:', len(train_input))\n",
    "print('test samples', len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=2,\n",
    "                                            max_value=512,\n",
    "                                            step=8,            \n",
    "#                                             sampling=\"log\"\n",
    "                                           ),\n",
    "                                            activation= 'relu',\n",
    "                                            \n",
    "#                                activation=hp.Choice('act_' + str(i), ['relu'])#, 'ELU', 'maxout', 'Leaky Relu' # adding other methods worsens the results\n",
    "                               \n",
    "#                                 kernel_regularizer=hp.Choice('act_' + str(i), ['l1', 'l2']) #is not helping at all\n",
    "                               \n",
    "                              ))\n",
    "#         for i in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "#         model.add(layers.Dropout(rate=hp.Float('D_rate_'+ str(i),\n",
    "#                                               min_value=0.0,\n",
    "#                                               max_value=1.0,\n",
    "#                                               step=0.1\n",
    "# #                                               sampling=\"log\"\n",
    "#                                               ),       \n",
    "#                                 ))\n",
    "\n",
    "#         model.add(layers.Dropout(rate=hp.Choice('dropout rate_'+ str(i),\n",
    "#                                              [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "#                                 ))\n",
    "    model.add(layers.Dense(1,\n",
    "#                            activation='linear'\n",
    "                          ))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [0.15, 0.1, 1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project Test_weights\\ANNTuning\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from Test_weights\\ANNTuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=  'val_loss',   #   'val_mean_absolute_error', #(['loss', 'mse', 'val_loss', 'val_mse']\n",
    "    max_trials=10,\n",
    "    executions_per_trial=10,\n",
    "    directory='Test_weights',\n",
    "    project_name='ANNTuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 38\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.15, 'conditions': [], 'values': [0.15, 0.1, 0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_3 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_4 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_5 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_6 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_6 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_7 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_7 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_8 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_8 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_9 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_9 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_10 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_10 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_11 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_12 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_12 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_13 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_13 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_14 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_14 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_15 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_15 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_16 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_16 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "units_17 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_17 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 12m 15s]\n",
      "val_loss: 0.030086887814104558\n",
      "\n",
      "Best val_loss So Far: 0.029775709100067615\n",
      "Total elapsed time: 01h 36m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "#     #normalization\n",
    "# normalizer=preprocessing.Normalization()\n",
    "#     #then adapt it to the data\n",
    "# norm_train_input= normalizer.adapt(np.array(train_input))\n",
    "    \n",
    "tuner.search(train_input, train_target,\n",
    "             epochs=50,\n",
    "             validation_data=(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Test_weights\\ANNTuning\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 11\n",
      "units_0: 394\n",
      "D_rate_0: 0.9\n",
      "learning_rate: 0.001\n",
      "units_1: 258\n",
      "D_rate_1: 0.8\n",
      "units_2: 322\n",
      "D_rate_2: 0.30000000000000004\n",
      "units_3: 250\n",
      "D_rate_3: 0.2\n",
      "units_4: 10\n",
      "D_rate_4: 0.9\n",
      "units_5: 442\n",
      "D_rate_5: 0.7000000000000001\n",
      "units_6: 202\n",
      "D_rate_6: 0.5\n",
      "units_7: 154\n",
      "D_rate_7: 0.1\n",
      "units_8: 82\n",
      "D_rate_8: 0.5\n",
      "units_9: 202\n",
      "D_rate_9: 0.9\n",
      "units_10: 354\n",
      "D_rate_10: 0.6000000000000001\n",
      "units_11: 130\n",
      "D_rate_11: 0.1\n",
      "units_12: 450\n",
      "D_rate_12: 0.1\n",
      "units_13: 410\n",
      "D_rate_13: 0.2\n",
      "units_14: 42\n",
      "D_rate_14: 0.2\n",
      "units_15: 106\n",
      "D_rate_15: 0.9\n",
      "units_16: 114\n",
      "D_rate_16: 0.5\n",
      "units_17: 234\n",
      "D_rate_17: 0.4\n",
      "units_18: 330\n",
      "units_19: 306\n",
      "Score: 0.029775709100067615\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 98\n",
      "D_rate_0: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_1: 26\n",
      "D_rate_1: 0.2\n",
      "units_2: 114\n",
      "D_rate_2: 0.30000000000000004\n",
      "units_3: 418\n",
      "D_rate_3: 1.0\n",
      "units_4: 386\n",
      "D_rate_4: 0.9\n",
      "units_5: 178\n",
      "D_rate_5: 0.30000000000000004\n",
      "units_6: 474\n",
      "D_rate_6: 0.30000000000000004\n",
      "units_7: 474\n",
      "D_rate_7: 0.2\n",
      "units_8: 330\n",
      "D_rate_8: 0.30000000000000004\n",
      "units_9: 482\n",
      "D_rate_9: 0.6000000000000001\n",
      "units_10: 2\n",
      "D_rate_10: 0.8\n",
      "units_11: 178\n",
      "D_rate_11: 0.5\n",
      "units_12: 354\n",
      "D_rate_12: 0.5\n",
      "units_13: 426\n",
      "D_rate_13: 0.7000000000000001\n",
      "units_14: 354\n",
      "D_rate_14: 0.5\n",
      "units_15: 274\n",
      "D_rate_15: 0.1\n",
      "units_16: 66\n",
      "D_rate_16: 0.6000000000000001\n",
      "units_17: 74\n",
      "D_rate_17: 0.1\n",
      "units_18: 378\n",
      "units_19: 26\n",
      "Score: 0.030086887814104558\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 10\n",
      "D_rate_0: 0.8\n",
      "learning_rate: 0.0001\n",
      "units_1: 450\n",
      "D_rate_1: 0.9\n",
      "units_2: 90\n",
      "D_rate_2: 0.8\n",
      "units_3: 50\n",
      "D_rate_3: 0.9\n",
      "units_4: 202\n",
      "D_rate_4: 0.7000000000000001\n",
      "units_5: 194\n",
      "D_rate_5: 0.30000000000000004\n",
      "units_6: 58\n",
      "D_rate_6: 0.1\n",
      "units_7: 34\n",
      "D_rate_7: 0.6000000000000001\n",
      "units_8: 170\n",
      "D_rate_8: 0.1\n",
      "units_9: 330\n",
      "D_rate_9: 0.4\n",
      "units_10: 442\n",
      "D_rate_10: 0.8\n",
      "units_11: 474\n",
      "D_rate_11: 0.5\n",
      "units_12: 498\n",
      "D_rate_12: 1.0\n",
      "units_13: 378\n",
      "D_rate_13: 0.2\n",
      "units_14: 370\n",
      "D_rate_14: 0.30000000000000004\n",
      "units_15: 378\n",
      "D_rate_15: 0.4\n",
      "units_16: 18\n",
      "D_rate_16: 0.7000000000000001\n",
      "units_17: 42\n",
      "D_rate_17: 0.6000000000000001\n",
      "Score: 0.030398373678326606\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 426\n",
      "D_rate_0: 0.0\n",
      "learning_rate: 0.0001\n",
      "units_1: 194\n",
      "D_rate_1: 0.9\n",
      "units_2: 162\n",
      "D_rate_2: 0.8\n",
      "units_3: 506\n",
      "D_rate_3: 0.4\n",
      "units_4: 50\n",
      "D_rate_4: 0.30000000000000004\n",
      "units_5: 394\n",
      "D_rate_5: 0.6000000000000001\n",
      "units_6: 314\n",
      "D_rate_6: 0.30000000000000004\n",
      "units_7: 210\n",
      "D_rate_7: 0.4\n",
      "units_8: 434\n",
      "D_rate_8: 0.30000000000000004\n",
      "units_9: 186\n",
      "D_rate_9: 0.1\n",
      "units_10: 66\n",
      "D_rate_10: 0.9\n",
      "units_11: 330\n",
      "D_rate_11: 0.9\n",
      "units_12: 74\n",
      "D_rate_12: 0.6000000000000001\n",
      "units_13: 202\n",
      "D_rate_13: 0.0\n",
      "units_14: 10\n",
      "D_rate_14: 1.0\n",
      "units_15: 234\n",
      "D_rate_15: 0.8\n",
      "units_16: 418\n",
      "D_rate_16: 0.2\n",
      "units_17: 274\n",
      "D_rate_17: 0.2\n",
      "Score: 0.031648884527385235\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 354\n",
      "D_rate_0: 0.5\n",
      "learning_rate: 0.0001\n",
      "units_1: 34\n",
      "D_rate_1: 0.2\n",
      "units_2: 354\n",
      "D_rate_2: 0.1\n",
      "units_3: 114\n",
      "D_rate_3: 0.2\n",
      "units_4: 90\n",
      "D_rate_4: 0.8\n",
      "units_5: 394\n",
      "D_rate_5: 0.30000000000000004\n",
      "units_6: 370\n",
      "D_rate_6: 1.0\n",
      "units_7: 402\n",
      "D_rate_7: 0.7000000000000001\n",
      "units_8: 226\n",
      "D_rate_8: 0.1\n",
      "units_9: 10\n",
      "D_rate_9: 0.9\n",
      "units_10: 370\n",
      "D_rate_10: 0.2\n",
      "units_11: 346\n",
      "D_rate_11: 0.4\n",
      "units_12: 146\n",
      "D_rate_12: 0.7000000000000001\n",
      "units_13: 122\n",
      "D_rate_13: 0.6000000000000001\n",
      "units_14: 466\n",
      "D_rate_14: 0.30000000000000004\n",
      "units_15: 506\n",
      "D_rate_15: 0.1\n",
      "units_16: 354\n",
      "D_rate_16: 0.4\n",
      "units_17: 426\n",
      "D_rate_17: 0.2\n",
      "Score: 0.03340199925005436\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 20\n",
      "units_0: 130\n",
      "D_rate_0: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 162\n",
      "D_rate_1: 0.6000000000000001\n",
      "units_2: 18\n",
      "D_rate_2: 0.8\n",
      "units_3: 378\n",
      "D_rate_3: 0.1\n",
      "units_4: 234\n",
      "D_rate_4: 0.5\n",
      "units_5: 370\n",
      "D_rate_5: 0.4\n",
      "units_6: 506\n",
      "D_rate_6: 0.6000000000000001\n",
      "units_7: 26\n",
      "D_rate_7: 0.8\n",
      "units_8: 10\n",
      "D_rate_8: 0.4\n",
      "units_9: 322\n",
      "D_rate_9: 0.4\n",
      "units_10: 314\n",
      "D_rate_10: 0.8\n",
      "units_11: 178\n",
      "D_rate_11: 0.9\n",
      "units_12: 362\n",
      "D_rate_12: 0.2\n",
      "units_13: 298\n",
      "D_rate_13: 0.4\n",
      "units_14: 442\n",
      "D_rate_14: 0.1\n",
      "units_15: 242\n",
      "D_rate_15: 1.0\n",
      "units_16: 10\n",
      "D_rate_16: 0.6000000000000001\n",
      "units_17: 50\n",
      "D_rate_17: 0.2\n",
      "units_18: 2\n",
      "units_19: 2\n",
      "Score: 0.07441260255873203\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 7\n",
      "units_0: 346\n",
      "D_rate_0: 0.6000000000000001\n",
      "learning_rate: 0.1\n",
      "units_1: 90\n",
      "D_rate_1: 0.2\n",
      "units_2: 506\n",
      "D_rate_2: 0.2\n",
      "units_3: 442\n",
      "D_rate_3: 0.1\n",
      "units_4: 122\n",
      "D_rate_4: 0.30000000000000004\n",
      "units_5: 42\n",
      "D_rate_5: 0.30000000000000004\n",
      "units_6: 426\n",
      "D_rate_6: 0.4\n",
      "units_7: 194\n",
      "D_rate_7: 1.0\n",
      "units_8: 218\n",
      "D_rate_8: 0.2\n",
      "units_9: 98\n",
      "D_rate_9: 0.8\n",
      "units_10: 482\n",
      "D_rate_10: 0.0\n",
      "units_11: 498\n",
      "D_rate_11: 0.5\n",
      "units_12: 42\n",
      "D_rate_12: 0.7000000000000001\n",
      "units_13: 506\n",
      "D_rate_13: 1.0\n",
      "units_14: 506\n",
      "D_rate_14: 0.5\n",
      "units_15: 458\n",
      "D_rate_15: 0.30000000000000004\n",
      "units_16: 106\n",
      "D_rate_16: 0.9\n",
      "units_17: 122\n",
      "D_rate_17: 0.8\n",
      "Score: 0.08545021712779999\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 17\n",
      "units_0: 402\n",
      "D_rate_0: 0.5\n",
      "learning_rate: 0.1\n",
      "units_1: 98\n",
      "D_rate_1: 0.8\n",
      "units_2: 282\n",
      "D_rate_2: 0.2\n",
      "units_3: 322\n",
      "D_rate_3: 0.6000000000000001\n",
      "units_4: 178\n",
      "D_rate_4: 0.2\n",
      "units_5: 474\n",
      "D_rate_5: 0.9\n",
      "units_6: 362\n",
      "D_rate_6: 0.0\n",
      "units_7: 10\n",
      "D_rate_7: 0.30000000000000004\n",
      "units_8: 74\n",
      "D_rate_8: 0.2\n",
      "units_9: 74\n",
      "D_rate_9: 0.8\n",
      "units_10: 130\n",
      "D_rate_10: 0.9\n",
      "units_11: 18\n",
      "D_rate_11: 0.1\n",
      "units_12: 154\n",
      "D_rate_12: 1.0\n",
      "units_13: 322\n",
      "D_rate_13: 0.6000000000000001\n",
      "units_14: 474\n",
      "D_rate_14: 0.4\n",
      "units_15: 234\n",
      "D_rate_15: 0.7000000000000001\n",
      "units_16: 154\n",
      "D_rate_16: 0.4\n",
      "units_17: 226\n",
      "D_rate_17: 0.4\n",
      "Score: 0.08545231446623802\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 506\n",
      "D_rate_0: 0.9\n",
      "learning_rate: 0.15\n",
      "units_1: 410\n",
      "D_rate_1: 0.0\n",
      "units_2: 378\n",
      "D_rate_2: 0.5\n",
      "units_3: 458\n",
      "D_rate_3: 0.7000000000000001\n",
      "units_4: 26\n",
      "D_rate_4: 0.7000000000000001\n",
      "units_5: 130\n",
      "D_rate_5: 0.5\n",
      "units_6: 58\n",
      "D_rate_6: 0.4\n",
      "units_7: 474\n",
      "D_rate_7: 0.7000000000000001\n",
      "units_8: 98\n",
      "D_rate_8: 0.7000000000000001\n",
      "units_9: 50\n",
      "D_rate_9: 0.0\n",
      "units_10: 146\n",
      "D_rate_10: 1.0\n",
      "units_11: 346\n",
      "D_rate_11: 0.4\n",
      "units_12: 362\n",
      "D_rate_12: 0.6000000000000001\n",
      "units_13: 482\n",
      "D_rate_13: 1.0\n",
      "units_14: 170\n",
      "D_rate_14: 0.0\n",
      "units_15: 418\n",
      "D_rate_15: 0.4\n",
      "units_16: 498\n",
      "D_rate_16: 0.5\n",
      "units_17: 442\n",
      "D_rate_17: 0.7000000000000001\n",
      "Score: 0.08545319139957427\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 18\n",
      "units_0: 98\n",
      "D_rate_0: 0.9\n",
      "learning_rate: 0.0001\n",
      "units_1: 2\n",
      "D_rate_1: 0.0\n",
      "units_2: 2\n",
      "D_rate_2: 0.0\n",
      "units_3: 2\n",
      "D_rate_3: 0.0\n",
      "units_4: 2\n",
      "D_rate_4: 0.0\n",
      "units_5: 2\n",
      "D_rate_5: 0.0\n",
      "units_6: 2\n",
      "D_rate_6: 0.0\n",
      "units_7: 2\n",
      "D_rate_7: 0.0\n",
      "units_8: 2\n",
      "D_rate_8: 0.0\n",
      "units_9: 2\n",
      "D_rate_9: 0.0\n",
      "units_10: 2\n",
      "D_rate_10: 0.0\n",
      "units_11: 2\n",
      "D_rate_11: 0.0\n",
      "units_12: 2\n",
      "D_rate_12: 0.0\n",
      "units_13: 2\n",
      "D_rate_13: 0.0\n",
      "units_14: 2\n",
      "D_rate_14: 0.0\n",
      "units_15: 2\n",
      "D_rate_15: 0.0\n",
      "units_16: 2\n",
      "D_rate_16: 0.0\n",
      "units_17: 2\n",
      "D_rate_17: 0.0\n",
      "Score: 0.8989066481590271\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,321\n",
      "Trainable params: 4,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# A function to hold preprocessor, layers, model and compiler \n",
    "def FFBackProp(inputs, output):\n",
    "   \n",
    "\n",
    "#     #normalization\n",
    "#     normalizer=preprocessing.Normalization()\n",
    "#     #then adapt it to the data\n",
    "#     normalizer.adapt(np.array(inputs))\n",
    "    \n",
    "    \n",
    "    model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32,activation=\"relu\", input_shape=(2,), \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    tf.keras.layers.Dense(64,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    tf.keras.layers.Dense(32,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "#     tf.keras.layers.Dense(32,activation=\"relu\", \n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "#     tf.keras.layers.Dense(64,activation=\"relu\",\n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.1),\n",
    "#     tf.keras.layers.Dense(64,activation=\"relu\",\n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    \n",
    "        #output layer\n",
    "    tf.keras.layers.Dense(1),\n",
    "  ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     compile the model\n",
    "    model1.compile(optimizer='adam',\n",
    "                loss='mean_absolute_error', #(from_logits=True),\n",
    "                metrics=[\"mse\"]\n",
    "               )\n",
    "    \n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "myFFBP= FFBackProp(train_input,train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-b3e0381a5ee5>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-b3e0381a5ee5>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    callbacks= keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "myFFBPtraining = myFFBP.fit(\n",
    "                            train_input, train_target,\n",
    "                            # Calculate validation results on 30% of the training data\n",
    "                            validation_split=0.3,\n",
    "\n",
    "\n",
    "                            validation_data=(test_input, test_target),\n",
    "\n",
    "\n",
    "                            # suppress logging\n",
    "                            verbose=0,\n",
    "\n",
    "#                             epochs=50,\n",
    "\n",
    "                            batch_size= 40,\n",
    "\n",
    "\n",
    "                            #early stopping\n",
    "                            #the fuction to stop the trianing by tracking the validation loss\n",
    "                            callbacks= keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "                            #to store callbacks in logs\n",
    "                        #     callbacks =[tb_callback]\n",
    ")\n",
    "\n",
    "\n",
    "myFFBP.evaluate(test_input, test_target,\n",
    "#                 callbacks=[tb_callback],\n",
    "                verbose=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_loss(arg):\n",
    "  plt.plot(arg.history['loss'], label='loss')\n",
    "  plt.plot(arg.history['val_loss'], label='val_loss')\n",
    "#   plt.ylim([0, 1])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [RHOB]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "plot_loss(myFFBPtraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = myFFBP.predict(test_input)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_target, predicted, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('True Values')\n",
    "ax.set_ylabel('Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn\n",
    "from sklearn import metrics\n",
    "print(\"r2 score: {}\".format(metrics.r2_score(test_target_actual, test_target_predicted)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error(test_target_actual, test_target_predicted)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error(test_target_actual, test_target_predicted))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error(test_target_actual, test_target_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
