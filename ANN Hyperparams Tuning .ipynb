{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment setup and the HParams experiment summary\n",
    "\n",
    "Experiment with  hyperparameters in the model:\n",
    "\n",
    "1. Number of units in the first dense layer\n",
    "2. Dropout rate in the dropout layer\n",
    "3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous log\n",
    "# rm -rvf logs\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# rm -rf 'logs/ANN/fit/'\n",
    "\n",
    "# rm -rvf logdir logs/ANN/fit/\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "xlsx = pd.ExcelFile('./Data/Outlier_thresh1_50.xlsx')\n",
    "df = pd.read_excel(xlsx, '1S 1X')\n",
    "dataset= df.copy()\n",
    "\n",
    "# Split the data into train and test\n",
    "\n",
    "# the 'sample' method takes a certain fraction randomly\n",
    "#Note that we use `random_state` to ensure the reproducibility of the examples.\n",
    "train_dataset = dataset.sample(frac=0.7, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "train_input = train_dataset.copy()\n",
    "test_input = test_dataset.copy()\n",
    "\n",
    "train_target = train_input.pop('RHOB')\n",
    "test_target = test_input.pop('RHOB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %reload_ext tensorboard\n",
    "\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = \"logs\\ANN\"\n",
    "\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment setup and the HParams experiment summary\n",
    "\n",
    "Experiment with  hyperparameters in the model:\n",
    "\n",
    "1. Number of units in the first dense layer\n",
    "2. Dropout rate in the dropout layer\n",
    "3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([300, 200,512]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 16, 32,64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.5))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(hp.HParam)\n",
    "\n",
    "# dir(hp)\n",
    "\n",
    "# help(    tf.keras.layers.Flatten())\n",
    "# help(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = \"mse\"\n",
    "\n",
    "with tf.summary.create_file_writer('logs/ANN/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC, display_name='mse')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt TensorFlow runs to log hyperparameters and metrics\n",
    "\n",
    "def create_model(hparams):\n",
    "    \n",
    "#normalization\n",
    "    normalizer=preprocessing.Normalization()\n",
    "    normalizer.adapt(np.array(test_input))\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu', input_shape=(5,)),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(1),\n",
    "  ])\n",
    "    \n",
    "    model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='mean_absolute_error',\n",
    "      metrics=['mse'],\n",
    "  )\n",
    "    \n",
    "#     logdir= 'logs/ANN/hparam_tuning/'\n",
    "#     model.fit(train_input, train_target,\n",
    "#               epochs=10,\n",
    "#                callbacks=[\n",
    "#         tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "#         hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "#     ],\n",
    "#               ) # Run with a few epoch to speed things up for demo purposes\n",
    "    \n",
    "    loss, mse = model.evaluate(test_input, test_target)\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each run, log an hparams summary with the hyperparameters and final mse:\n",
    "\n",
    "def experiment(experiment_dir, hparams):\n",
    "     with tf.summary.create_file_writer(experiment_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        mse = create_model(hparams)\n",
    "        tf.summary.scalar(METRIC, mse, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use keras callbacks when traing\n",
    "\n",
    "logdir= 'logs/ANN/hparam_tuning/'\n",
    "\n",
    "model.fit(\n",
    "    ...,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_no = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,}\n",
    "\n",
    "            experiment_name = f'Experiment {experiment_no}'\n",
    "            print(f'Starting Experiment: {experiment_name}')\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            experiment('logs/ANN/hparam_tuning/' + experiment_name, hparams)\n",
    "            experiment_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualize the results in TensorBoard's HParams plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard -- logdir= \"logs/ANN/hparam_tuning/\" --port=6005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using sckit-learn for Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunables in ANN\n",
    "1. Batch and Epoch\n",
    "2. Optimization algorithm\n",
    "3. Learning Rate and Momentum\n",
    "4. Weight initialization\n",
    "5. Activation Functions\n",
    "6. Neuron Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing necesary packages\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# dir(keras.wrappers.scikit_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1 - Tuning batch and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RHOB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RHOB'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2552e1f68ab4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RHOB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RHOB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4365\u001b[0m         \u001b[1;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4366\u001b[0m         \"\"\"\n\u001b[1;32m-> 4367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4369\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Series\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RHOB'"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "xlsx = pd.ExcelFile('./Data/Outlier_thresh1_50.xlsx')\n",
    "df = pd.read_excel(xlsx, '1S 5X')\n",
    "dataset= df.copy()\n",
    "\n",
    "\n",
    "# Split the data into train and test\n",
    "\n",
    "# the 'sample' method takes a certain fraction randomly\n",
    "#Note that we use `random_state` to ensure the reproducibility of the examples.\n",
    "train_dataset = dataset.sample(frac=0.7, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "train_input = train_dataset.copy()\n",
    "test_input = test_dataset.copy()\n",
    "\n",
    "train_target = train_input.pop('RHOB')\n",
    "test_target = test_input.pop('RHOB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model,for KerasClassifier\n",
    "def create_my_model():\n",
    "    #defining my model\n",
    "    mymodel = Sequential()\n",
    "    mymodel.add(Dense(32, input_dim=5, activation='relu'))\n",
    "    mymodel.add(Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    mymodel.compile(loss='mae', optimizer='adam', metrics=['mse'])\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasRegressor(build_fn=create_my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batchSize = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [5,10, 30, 50,70,100,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = dict(batch_size=batchSize, epochs=epochs)\n",
    "\n",
    "\n",
    "mygrid = GridSearchCV(estimator=model, param_grid=parameter_grid, n_jobs=-1, cv=3)\n",
    "grid_result = mygrid.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2- Optimizing Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def create_my_model(optimizer='adam'):\n",
    "    # create model\n",
    "    mymodel = Sequential()\n",
    "    mymodel.add(Dense(32, input_dim=5, activation='relu'))\n",
    "    mymodel.add(Dense(1))\n",
    "    # Compile model\n",
    "    mymodel.compile(loss='mae', optimizer=optimizer, metrics=['mse'])\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasRegressor(build_fn=create_my_model, epochs=50, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "optimizer = ['SGD','Adadelta', 'RMSprop', 'Adagrad','Adam','Adamax']\n",
    "parameter_grid = dict(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=parameter_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Params={'batch_size': 40, 'epochs': 50, 'optimizer': 'SGD'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras-Tuner\n",
    "keras Tuner- Decide Number of Hidden Layers And Neuron In Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "1. How many number of hidden layers we should have? <br>\n",
    "    <em>Dense vrs dropout</em>\n",
    "2. How many number of neurons we should have in hidden layers?\n",
    "3. Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous log\n",
    "# rm -rvf Test_weights\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# rm -rf 'logs/ANN/fit/'\n",
    "\n",
    "# rm -rvf logdir Test_weights\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "# rm -rf Test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=2,\n",
    "                                            max_value=512,\n",
    "                                            step=8,            \n",
    "#                                             sampling=\"log\"\n",
    "                                           ),\n",
    "                                            activation= 'relu',\n",
    "                                            \n",
    "#                                activation=hp.Choice('act_' + str(i), ['relu'])#, 'ELU', 'maxout', 'Leaky Relu' # adding other methods worsens the results\n",
    "                               \n",
    "#                                 kernel_regularizer=hp.Choice('act_' + str(i), ['l1', 'l2']) #is not helping at all\n",
    "                               \n",
    "                              ))\n",
    "        \n",
    "        model.add(layers.Dropout(rate=hp.Float('D_rate_'+ str(i),\n",
    "                                              min_value=0.0,\n",
    "                                              max_value=1,\n",
    "                                              step=0.1\n",
    "#                                               sampling=\"log\"\n",
    "                                              ),       \n",
    "                                ))\n",
    "\n",
    "#         model.add(layers.Dropout(rate=hp.Choice('dropout rate_'+ str(i),\n",
    "#                                              [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "#                                 ))\n",
    "    model.add(layers.Dense(1,\n",
    "#                            activation='linear'\n",
    "                          ))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [0.15, 0.1, 1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective =  'val_loss',   #   'val_mean_absolute_error', #(['loss', 'mse', 'val_loss', 'val_mse']\n",
    "    max_trials=10,\n",
    "    executions_per_trial=6,\n",
    "    directory='Test_weights',\n",
    "    project_name='ANNTuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "D_rate_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.15, 'conditions': [], 'values': [0.15, 0.1, 0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 14s]\n",
      "val_loss: 0.15094660222530365\n",
      "\n",
      "Best val_loss So Far: 0.15033872425556183\n",
      "Total elapsed time: 00h 15m 06s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |13                |4                 \n",
      "units_0           |394               |322               \n",
      "D_rate_0          |0.2               |0.7               \n",
      "learning_rate     |0.001             |0.001             \n",
      "units_1           |282               |26                \n",
      "D_rate_1          |0.9               |0.6               \n",
      "units_2           |322               |458               \n",
      "D_rate_2          |0.9               |0.6               \n",
      "units_3           |306               |18                \n",
      "D_rate_3          |0.4               |0.2               \n",
      "units_4           |354               |138               \n",
      "D_rate_4          |0.9               |0.7               \n",
      "units_5           |194               |178               \n",
      "D_rate_5          |0.2               |0.1               \n",
      "units_6           |394               |410               \n",
      "D_rate_6          |0.6               |1                 \n",
      "units_7           |274               |186               \n",
      "D_rate_7          |0.7               |0.7               \n",
      "units_8           |354               |130               \n",
      "D_rate_8          |1                 |0.2               \n",
      "units_9           |250               |210               \n",
      "D_rate_9          |0.1               |0.3               \n",
      "units_10          |386               |170               \n",
      "D_rate_10         |0.5               |0.9               \n",
      "units_11          |394               |298               \n",
      "D_rate_11         |0.2               |0.9               \n",
      "units_12          |394               |474               \n",
      "D_rate_12         |0.1               |1                 \n",
      "units_13          |378               |274               \n",
      "D_rate_13         |0.3               |0.2               \n",
      "units_14          |466               |434               \n",
      "D_rate_14         |0.1               |0.3               \n",
      "units_15          |346               |26                \n",
      "D_rate_15         |0.1               |1                 \n",
      "units_16          |194               |66                \n",
      "D_rate_16         |0.6               |0.1               \n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:216 call\n        output = tf_utils.smart_cond(training,\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54 smart_cond\n        return true_fn()\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:210 dropped_inputs\n        return nn.dropout(\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4942 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5022 dropout_v2\n        raise ValueError(\"rate must be a scalar tensor or a float in the \"\n\n    ValueError: rate must be a scalar tensor or a float in the range [0, 1), got 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0e63d9507758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# norm_train_input= normalizer.adapt(np.array(train_input))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m tuner.search(train_input, train_target,\n\u001b[0m\u001b[0;32m      8\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m              validation_data=(test_input, test_target))\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:216 call\n        output = tf_utils.smart_cond(training,\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py:64 smart_cond\n        return smart_module.smart_cond(\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54 smart_cond\n        return true_fn()\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:210 dropped_inputs\n        return nn.dropout(\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4942 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5022 dropout_v2\n        raise ValueError(\"rate must be a scalar tensor or a float in the \"\n\n    ValueError: rate must be a scalar tensor or a float in the range [0, 1), got 1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "#     #normalization\n",
    "# normalizer=preprocessing.Normalization()\n",
    "#     #then adapt it to the data\n",
    "# norm_train_input= normalizer.adapt(np.array(train_input))\n",
    "    \n",
    "tuner.search(train_input, train_target,\n",
    "             epochs=50,\n",
    "             validation_data=(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 1\n",
    "units_0: 34\n",
    "learning_rate: 0.001\n",
    "units_1: 482\n",
    "units_2: 418\n",
    "units_3: 258\n",
    "units_4: 450\n",
    "units_5: 290\n",
    "units_6: 322\n",
    "units_7: 354\n",
    "units_8: 130\n",
    "units_9: 482\n",
    "units_10: 354\n",
    "units_11: 66\n",
    "units_12: 386\n",
    "units_13: 322\n",
    "units_14: 66\n",
    "Score: 0.12417174875736237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# A function to hold preprocessor, layers, model and compiler \n",
    "def FFBackProp(inputs, output):\n",
    "   \n",
    "\n",
    "#     #normalization\n",
    "#     normalizer=preprocessing.Normalization()\n",
    "#     #then adapt it to the data\n",
    "#     normalizer.adapt(np.array(inputs))\n",
    "    \n",
    "    \n",
    "    model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32,activation=\"relu\", input_shape=(5,), \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    tf.keras.layers.Dense(64,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "        \n",
    "    tf.keras.layers.Dense(32,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "#     tf.keras.layers.Dense(32,activation=\"relu\", \n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "#     tf.keras.layers.Dense(64,activation=\"relu\",\n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.1),\n",
    "#     tf.keras.layers.Dense(64,activation=\"relu\",\n",
    "# #                           kernel_regularizer=\"l2\"\n",
    "#                          ),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "    \n",
    "        #output layer\n",
    "    tf.keras.layers.Dense(1),\n",
    "  ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     compile the model\n",
    "    model1.compile(optimizer='adam',\n",
    "                loss='mean_absolute_error', #(from_logits=True),\n",
    "                metrics=[\"mse\"]\n",
    "               )\n",
    "    \n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "myFFBP= FFBackProp(train_input,train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myFFBPtraining = myFFBP.fit(\n",
    "                            train_input, train_target,\n",
    "                            # Calculate validation results on 30% of the training data\n",
    "                            validation_split=0.3,\n",
    "\n",
    "\n",
    "                            validation_data=(test_input, test_target),\n",
    "\n",
    "\n",
    "                            # suppress logging\n",
    "                            verbose=0,\n",
    "\n",
    "                            epochs=50,\n",
    "\n",
    "                            batch_size= 40\n",
    "\n",
    "\n",
    "                            #early stopping\n",
    "                            #the fuction to stop the trianing by tracking the validation loss\n",
    "                            #callbacks= keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)\n",
    "\n",
    "                            #to store callbacks in logs\n",
    "                        #     callbacks =[tb_callback]\n",
    ")\n",
    "\n",
    "\n",
    "myFFBP.evaluate(test_input, test_target,\n",
    "#                 callbacks=[tb_callback],\n",
    "                verbose=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_loss(arg):\n",
    "  plt.plot(arg.history['loss'], label='loss')\n",
    "  plt.plot(arg.history['val_loss'], label='val_loss')\n",
    "#   plt.ylim([0, 1])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [RHOB]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "plot_loss(myFFBPtraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = myFFBP.predict(test_input)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(test_target, predicted, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('True Values')\n",
    "ax.set_ylabel('Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn\n",
    "from sklearn import metrics\n",
    "print(\"r2 score: {}\".format(metrics.r2_score(test_target_actual, test_target_predicted)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error(test_target_actual, test_target_predicted)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error(test_target_actual, test_target_predicted))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error(test_target_actual, test_target_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict from a diff well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile('./Data/Outliers_out.xlsx')\n",
    "df2 = pd.read_excel(xlsx, '1x 4s')\n",
    "dataset2= df2.copy()\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "inputs2 = dataset2.copy()\n",
    "target2 = inputs2.pop('RHOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = model.predict(test_input)\n",
    "\n",
    "predicted2 = myFFBP.predict(inputs2)\n",
    "fig, ax= plt.subplots()\n",
    "ax.scatter(target2,predicted2, alpha=0.5)\n",
    "ax.set_xlabel(\"True\")\n",
    "ax.set_ylabel(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2 score: {}\".format(metrics.r2_score( target2, predicted2)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error( target2, predicted2)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error( target2, predicted2))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error( target2, predicted2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
