{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn import datasets, metrics, model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.398520</td>\n",
       "      <td>2.499091</td>\n",
       "      <td>0.178797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.403833</td>\n",
       "      <td>2.489971</td>\n",
       "      <td>0.105971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.451285</td>\n",
       "      <td>2.485884</td>\n",
       "      <td>0.033656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.515515</td>\n",
       "      <td>2.479439</td>\n",
       "      <td>-0.027975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.560541</td>\n",
       "      <td>2.492715</td>\n",
       "      <td>-0.047035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>13852</td>\n",
       "      <td>0.962859</td>\n",
       "      <td>-2.179569</td>\n",
       "      <td>-2.287310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>13853</td>\n",
       "      <td>0.938350</td>\n",
       "      <td>-2.179777</td>\n",
       "      <td>-2.362097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>13854</td>\n",
       "      <td>0.894981</td>\n",
       "      <td>-2.185274</td>\n",
       "      <td>-2.387264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>13855</td>\n",
       "      <td>0.858602</td>\n",
       "      <td>-2.230196</td>\n",
       "      <td>-2.407852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>13856</td>\n",
       "      <td>0.831630</td>\n",
       "      <td>-2.309509</td>\n",
       "      <td>-2.459917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index       PC1       PC2       PC3\n",
       "0          0 -3.398520  2.499091  0.178797\n",
       "1          1 -3.403833  2.489971  0.105971\n",
       "2          2 -3.451285  2.485884  0.033656\n",
       "3          3 -3.515515  2.479439 -0.027975\n",
       "4          4 -3.560541  2.492715 -0.047035\n",
       "...      ...       ...       ...       ...\n",
       "13852  13852  0.962859 -2.179569 -2.287310\n",
       "13853  13853  0.938350 -2.179777 -2.362097\n",
       "13854  13854  0.894981 -2.185274 -2.387264\n",
       "13855  13855  0.858602 -2.230196 -2.407852\n",
       "13856  13856  0.831630 -2.309509 -2.459917\n",
       "\n",
       "[13857 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile('Feat_extracts well1.xlsx')\n",
    "df = pd.read_excel(xlsx, 'PCAs')\n",
    "dataset_pca= df.copy()\n",
    "dataset_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.398520</td>\n",
       "      <td>2.499091</td>\n",
       "      <td>0.178797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.403833</td>\n",
       "      <td>2.489971</td>\n",
       "      <td>0.105971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.451285</td>\n",
       "      <td>2.485884</td>\n",
       "      <td>0.033656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.515515</td>\n",
       "      <td>2.479439</td>\n",
       "      <td>-0.027975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.560541</td>\n",
       "      <td>2.492715</td>\n",
       "      <td>-0.047035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>0.962859</td>\n",
       "      <td>-2.179569</td>\n",
       "      <td>-2.287310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>0.938350</td>\n",
       "      <td>-2.179777</td>\n",
       "      <td>-2.362097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>0.894981</td>\n",
       "      <td>-2.185274</td>\n",
       "      <td>-2.387264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>0.858602</td>\n",
       "      <td>-2.230196</td>\n",
       "      <td>-2.407852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>0.831630</td>\n",
       "      <td>-2.309509</td>\n",
       "      <td>-2.459917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13857 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3\n",
       "0     -3.398520  2.499091  0.178797\n",
       "1     -3.403833  2.489971  0.105971\n",
       "2     -3.451285  2.485884  0.033656\n",
       "3     -3.515515  2.479439 -0.027975\n",
       "4     -3.560541  2.492715 -0.047035\n",
       "...         ...       ...       ...\n",
       "13852  0.962859 -2.179569 -2.287310\n",
       "13853  0.938350 -2.179777 -2.362097\n",
       "13854  0.894981 -2.185274 -2.387264\n",
       "13855  0.858602 -2.230196 -2.407852\n",
       "13856  0.831630 -2.309509 -2.459917\n",
       "\n",
       "[13857 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset_pca.pop('index')\n",
    "\n",
    "# dataset_pca1= dataset_pca('PC1','PC1','PC3')\n",
    "dataset_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RHOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.24710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.25890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13852</th>\n",
       "      <td>2.52625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13853</th>\n",
       "      <td>2.52590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13854</th>\n",
       "      <td>2.52555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>2.52520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13856</th>\n",
       "      <td>2.53310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13857 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RHOB\n",
       "0      2.24710\n",
       "1      2.25870\n",
       "2      2.25890\n",
       "3      2.25460\n",
       "4      2.25150\n",
       "...        ...\n",
       "13852  2.52625\n",
       "13853  2.52590\n",
       "13854  2.52555\n",
       "13855  2.52520\n",
       "13856  2.53310\n",
       "\n",
       "[13857 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import treated data\n",
    "\n",
    "xlsx_3 = pd.ExcelFile('Feat_extracts well1.xlsx')\n",
    "df_3 = pd.read_excel(xlsx_3, 'target')\n",
    "pca_target= df_3.copy()\n",
    "\n",
    "pca_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 9699\n",
      "test samples 4158\n"
     ]
    }
   ],
   "source": [
    "train_input, test_input, train_target, test_target = model_selection.train_test_split(dataset_pca, pca_target['RHOB'], train_size=0.7)\n",
    "\n",
    "print('train samples:', len(train_input))\n",
    "print('test samples', len(test_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.73163915  2.51697914  0.14781493 ... -2.87725798 -0.02998333\n",
      "  -3.06763472]\n",
      " [-1.73081574  2.52923055  0.4129627  ... -2.93944911 -0.31479146\n",
      "  -3.7477384 ]\n",
      " [-1.72999232  2.54148197  0.80347369 ... -3.00164023 -0.25737338\n",
      "  -4.21784884]\n",
      " ...\n",
      " [ 1.72999232 -0.57576699 -0.63341287 ...  0.06032096 -0.12310411\n",
      "   1.7543647 ]\n",
      " [ 1.73081574 -0.57596783 -0.60694777 ...  0.14599241 -0.13214277\n",
      "   1.74230317]\n",
      " [ 1.73163915 -0.57616867 -0.90593453 ...  0.15804987 -0.15340622\n",
      "   1.7008101 ]]\n",
      "train samples: 2944\n",
      "test samples 1263\n"
     ]
    }
   ],
   "source": [
    "# non pcas\n",
    "\n",
    "xlsx = pd.ExcelFile('./Data/Outlier_thresh1_50.xlsx')\n",
    "df = pd.read_excel(xlsx, '1S 4X')\n",
    "dataset1= df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "Sd_scaler1 =scaler1.fit(dataset1)\n",
    "data1_Sd= Sd_scaler1.transform(dataset1)\n",
    "print(data1_Sd)\n",
    "    \n",
    "    #convert to dataframe\n",
    "dataset= pd.DataFrame(data1_Sd, columns=dataset1.keys())\n",
    "\n",
    "\n",
    "\n",
    "# split datat into input and target\n",
    "\n",
    "inputs = dataset.copy()\n",
    "\n",
    "target = inputs.pop('RHOB')\n",
    "\n",
    "\n",
    "train_input, test_input, train_target, test_target = model_selection.train_test_split(inputs, target, train_size=0.7)\n",
    "\n",
    "print('train samples:', len(train_input))\n",
    "print('test samples', len(test_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DEPTH      CALI        GR       ILD       ITT       LLD       LLS  \\\n",
      "0    -1.731639  2.516979  0.147815  0.637840 -0.317773 -0.311624 -0.309417   \n",
      "1    -1.730816  2.529231  0.412963 -0.218280 -0.412743 -0.314144 -0.323037   \n",
      "2    -1.729992  2.541482  0.803474 -0.114471 -0.507713 -0.313667 -0.336657   \n",
      "3    -1.729169  2.553733  1.058458  0.136484 -0.602683 -0.307471 -0.350277   \n",
      "4    -1.728345  2.565985  1.026933  0.278547 -0.593186 -0.306495 -0.363896   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "4202  1.728345 -0.575181 -0.686343 -0.077954 -1.386187 -0.057868  0.009181   \n",
      "4203  1.729169 -0.575474 -0.659878 -0.065343 -1.362445 -0.125620 -0.082412   \n",
      "4204  1.729992 -0.575767 -0.633413 -0.044466 -1.343451 -0.147659 -0.157118   \n",
      "4205  1.730816 -0.575968 -0.606948 -0.023588 -1.329205 -0.169698 -0.164358   \n",
      "4206  1.731639 -0.576169 -0.905935 -0.002710 -1.357696 -0.140328 -0.143169   \n",
      "\n",
      "          MSFL      NPHI      RHOB       SFL        SP  \n",
      "0    -0.685180  1.331626 -2.877258 -0.029983 -3.067635  \n",
      "1    -0.685559  1.492952 -2.939449 -0.314791 -3.747738  \n",
      "2    -0.685904  1.654278 -3.001640 -0.257373 -4.217849  \n",
      "3    -0.685559  1.653294 -3.063831 -0.054320 -4.944131  \n",
      "4    -0.685870  1.548039 -3.126022  0.148734 -5.242861  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "4202 -0.267572 -0.932841 -0.008639 -0.090701  1.709306  \n",
      "4203 -0.270226 -0.970221 -0.029158 -0.109388  1.746619  \n",
      "4204 -0.272881 -1.007602  0.060321 -0.123104  1.754365  \n",
      "4205 -0.275536 -1.044982  0.145992 -0.132143  1.742303  \n",
      "4206 -0.278190 -1.082362  0.158050 -0.153406  1.700810  \n",
      "\n",
      "[4207 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning batch and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Function to create model,for KerasClassifier\n",
    "def create_my_model():\n",
    "    #defining my model\n",
    "    mymodel = Sequential()\n",
    "    mymodel.add(Dense(32, input_dim=3, activation='relu'))\n",
    "    mymodel.add(Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    mymodel.compile(loss='mae', optimizer='adam', metrics=['mse'])\n",
    "    return mymodel\n",
    "\n",
    "# create model\n",
    "model_BE = KerasRegressor(build_fn=create_my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "485/485 [==============================] - 0s 496us/step - loss: 0.6773 - mse: 1.0402\n",
      "Epoch 2/150\n",
      "485/485 [==============================] - 0s 452us/step - loss: 0.0713 - mse: 0.0103\n",
      "Epoch 3/150\n",
      "485/485 [==============================] - 0s 457us/step - loss: 0.0502 - mse: 0.0048\n",
      "Epoch 4/150\n",
      "485/485 [==============================] - 0s 460us/step - loss: 0.0465 - mse: 0.0041\n",
      "Epoch 5/150\n",
      "485/485 [==============================] - 0s 421us/step - loss: 0.0445 - mse: 0.0039\n",
      "Epoch 6/150\n",
      "485/485 [==============================] - 0s 477us/step - loss: 0.0433 - mse: 0.0037\n",
      "Epoch 7/150\n",
      "485/485 [==============================] - 0s 462us/step - loss: 0.0423 - mse: 0.0035\n",
      "Epoch 8/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0415 - mse: 0.0034\n",
      "Epoch 9/150\n",
      "485/485 [==============================] - 0s 422us/step - loss: 0.0402 - mse: 0.0032\n",
      "Epoch 10/150\n",
      "485/485 [==============================] - 0s 427us/step - loss: 0.0402 - mse: 0.0032\n",
      "Epoch 11/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0405 - mse: 0.0033\n",
      "Epoch 12/150\n",
      "485/485 [==============================] - 0s 500us/step - loss: 0.0398 - mse: 0.0032\n",
      "Epoch 13/150\n",
      "485/485 [==============================] - 0s 450us/step - loss: 0.0391 - mse: 0.0030\n",
      "Epoch 14/150\n",
      "485/485 [==============================] - 0s 423us/step - loss: 0.0390 - mse: 0.0030\n",
      "Epoch 15/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0388 - mse: 0.0030\n",
      "Epoch 16/150\n",
      "485/485 [==============================] - 0s 434us/step - loss: 0.0393 - mse: 0.0030\n",
      "Epoch 17/150\n",
      "485/485 [==============================] - 0s 450us/step - loss: 0.0389 - mse: 0.0030\n",
      "Epoch 18/150\n",
      "485/485 [==============================] - 0s 498us/step - loss: 0.0392 - mse: 0.0030\n",
      "Epoch 19/150\n",
      "485/485 [==============================] - 0s 457us/step - loss: 0.0382 - mse: 0.0029\n",
      "Epoch 20/150\n",
      "485/485 [==============================] - 0s 425us/step - loss: 0.0381 - mse: 0.0029\n",
      "Epoch 21/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0380 - mse: 0.0029\n",
      "Epoch 22/150\n",
      "485/485 [==============================] - 0s 674us/step - loss: 0.0380 - mse: 0.0029\n",
      "Epoch 23/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0376 - mse: 0.0028\n",
      "Epoch 24/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0374 - mse: 0.0028\n",
      "Epoch 25/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0375 - mse: 0.0028\n",
      "Epoch 26/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0377 - mse: 0.0027\n",
      "Epoch 27/150\n",
      "485/485 [==============================] - 0s 435us/step - loss: 0.0374 - mse: 0.0028\n",
      "Epoch 28/150\n",
      "485/485 [==============================] - 0s 427us/step - loss: 0.0376 - mse: 0.0028\n",
      "Epoch 29/150\n",
      "485/485 [==============================] - 0s 452us/step - loss: 0.0370 - mse: 0.0027\n",
      "Epoch 30/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0374 - mse: 0.0028\n",
      "Epoch 31/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0367 - mse: 0.0027\n",
      "Epoch 32/150\n",
      "485/485 [==============================] - 0s 432us/step - loss: 0.0370 - mse: 0.0027\n",
      "Epoch 33/150\n",
      "485/485 [==============================] - 0s 432us/step - loss: 0.0369 - mse: 0.0027\n",
      "Epoch 34/150\n",
      "485/485 [==============================] - 0s 437us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 35/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0365 - mse: 0.0026\n",
      "Epoch 36/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 37/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 38/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 39/150\n",
      "485/485 [==============================] - 0s 443us/step - loss: 0.0365 - mse: 0.0026\n",
      "Epoch 40/150\n",
      "485/485 [==============================] - 0s 432us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 41/150\n",
      "485/485 [==============================] - 0s 445us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 42/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0369 - mse: 0.0027\n",
      "Epoch 43/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 44/150\n",
      "485/485 [==============================] - 0s 454us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 45/150\n",
      "485/485 [==============================] - 0s 425us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 46/150\n",
      "485/485 [==============================] - 0s 469us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 47/150\n",
      "485/485 [==============================] - 0s 449us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 48/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0368 - mse: 0.0027\n",
      "Epoch 49/150\n",
      "485/485 [==============================] - 0s 447us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 50/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 51/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0365 - mse: 0.0026\n",
      "Epoch 52/150\n",
      "485/485 [==============================] - 0s 425us/step - loss: 0.0359 - mse: 0.0026\n",
      "Epoch 53/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0366 - mse: 0.0027\n",
      "Epoch 54/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 55/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 56/150\n",
      "485/485 [==============================] - 0s 422us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 57/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 58/150\n",
      "485/485 [==============================] - 0s 411us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 59/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 60/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 61/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 62/150\n",
      "485/485 [==============================] - 0s 440us/step - loss: 0.0366 - mse: 0.0026\n",
      "Epoch 63/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 64/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 65/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 66/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 67/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 68/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 69/150\n",
      "485/485 [==============================] - 0s 426us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 70/150\n",
      "485/485 [==============================] - 0s 407us/step - loss: 0.0365 - mse: 0.0026\n",
      "Epoch 71/150\n",
      "485/485 [==============================] - 0s 444us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 72/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0359 - mse: 0.0025\n",
      "Epoch 73/150\n",
      "485/485 [==============================] - 0s 453us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 74/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 75/150\n",
      "485/485 [==============================] - 0s 434us/step - loss: 0.0365 - mse: 0.0026\n",
      "Epoch 76/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 77/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 78/150\n",
      "485/485 [==============================] - 0s 435us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 79/150\n",
      "485/485 [==============================] - 0s 451us/step - loss: 0.0359 - mse: 0.0025\n",
      "Epoch 80/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0354 - mse: 0.0024\n",
      "Epoch 81/150\n",
      "485/485 [==============================] - 0s 440us/step - loss: 0.0364 - mse: 0.0026\n",
      "Epoch 82/150\n",
      "485/485 [==============================] - 0s 449us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 83/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 84/150\n",
      "485/485 [==============================] - 0s 432us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 85/150\n",
      "485/485 [==============================] - 0s 447us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 86/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 87/150\n",
      "485/485 [==============================] - 0s 416us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 88/150\n",
      "485/485 [==============================] - 0s 434us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 89/150\n",
      "485/485 [==============================] - 0s 437us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 90/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 91/150\n",
      "485/485 [==============================] - 0s 440us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 92/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0359 - mse: 0.0025\n",
      "Epoch 93/150\n",
      "485/485 [==============================] - 0s 434us/step - loss: 0.0361 - mse: 0.0025\n",
      "Epoch 94/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0352 - mse: 0.0024\n",
      "Epoch 95/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 96/150\n",
      "485/485 [==============================] - 0s 460us/step - loss: 0.0359 - mse: 0.0025\n",
      "Epoch 97/150\n",
      "485/485 [==============================] - 0s 451us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 98/150\n",
      "485/485 [==============================] - 0s 440us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 99/150\n",
      "485/485 [==============================] - 0s 454us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 100/150\n",
      "485/485 [==============================] - 0s 463us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 101/150\n",
      "485/485 [==============================] - 0s 427us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 102/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 103/150\n",
      "485/485 [==============================] - 0s 443us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 104/150\n",
      "485/485 [==============================] - 0s 423us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 105/150\n",
      "485/485 [==============================] - 0s 432us/step - loss: 0.0360 - mse: 0.0025\n",
      "Epoch 106/150\n",
      "485/485 [==============================] - 0s 446us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 107/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 108/150\n",
      "485/485 [==============================] - 0s 435us/step - loss: 0.0363 - mse: 0.0026\n",
      "Epoch 109/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0359 - mse: 0.0025\n",
      "Epoch 110/150\n",
      "485/485 [==============================] - 0s 424us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 111/150\n",
      "485/485 [==============================] - 0s 433us/step - loss: 0.0351 - mse: 0.0024\n",
      "Epoch 112/150\n",
      "485/485 [==============================] - 0s 427us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 113/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 114/150\n",
      "485/485 [==============================] - 0s 412us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 115/150\n",
      "485/485 [==============================] - 0s 409us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 116/150\n",
      "485/485 [==============================] - 0s 419us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 117/150\n",
      "485/485 [==============================] - 0s 427us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 118/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 119/150\n",
      "485/485 [==============================] - 0s 424us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 120/150\n",
      "485/485 [==============================] - 0s 478us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 121/150\n",
      "485/485 [==============================] - 0s 453us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 122/150\n",
      "485/485 [==============================] - 0s 436us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 123/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 124/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 125/150\n",
      "485/485 [==============================] - 0s 447us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 126/150\n",
      "485/485 [==============================] - 0s 421us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 127/150\n",
      "485/485 [==============================] - 0s 425us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 128/150\n",
      "485/485 [==============================] - 0s 438us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 129/150\n",
      "485/485 [==============================] - 0s 420us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 130/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 131/150\n",
      "485/485 [==============================] - 0s 423us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 132/150\n",
      "485/485 [==============================] - 0s 435us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 133/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 134/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0353 - mse: 0.0024\n",
      "Epoch 135/150\n",
      "485/485 [==============================] - 0s 430us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 136/150\n",
      "485/485 [==============================] - 0s 457us/step - loss: 0.0362 - mse: 0.0026\n",
      "Epoch 137/150\n",
      "485/485 [==============================] - 0s 439us/step - loss: 0.0353 - mse: 0.0024\n",
      "Epoch 138/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 139/150\n",
      "485/485 [==============================] - 0s 416us/step - loss: 0.0353 - mse: 0.0024\n",
      "Epoch 140/150\n",
      "485/485 [==============================] - 0s 426us/step - loss: 0.0350 - mse: 0.0024\n",
      "Epoch 141/150\n",
      "485/485 [==============================] - 0s 429us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 142/150\n",
      "485/485 [==============================] - 0s 426us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 143/150\n",
      "485/485 [==============================] - 0s 442us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 144/150\n",
      "485/485 [==============================] - 0s 424us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 145/150\n",
      "485/485 [==============================] - 0s 443us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 146/150\n",
      "485/485 [==============================] - 0s 428us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 147/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0358 - mse: 0.0025\n",
      "Epoch 148/150\n",
      "485/485 [==============================] - 0s 471us/step - loss: 0.0363 - mse: 0.0025\n",
      "Epoch 149/150\n",
      "485/485 [==============================] - 0s 437us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 150/150\n",
      "485/485 [==============================] - 0s 431us/step - loss: 0.0360 - mse: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "batchSize = [10, 20, 40, 50, 60, 80, 100]\n",
    "epochs = [5,10,15, 30, 50,70,100,150]\n",
    "\n",
    "parameter_grid = dict(batch_size=batchSize, epochs=epochs)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "mygrid = GridSearchCV(estimator=model_BE, param_grid=parameter_grid, n_jobs=-1, cv=3)\n",
    "grid_result = mygrid.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "# Function to create model\n",
    "def create_my_model(optimizer='adam'):\n",
    "    # create model\n",
    "    mymodel = Sequential()\n",
    "    mymodel.add(Dense(32, input_dim=3, activation='relu'))\n",
    "    mymodel.add(Dense(1))\n",
    "    # Compile model\n",
    "    mymodel.compile(loss='mae', optimizer=optimizer, metrics=['mse'])\n",
    "    return mymodel\n",
    "\n",
    "# create model\n",
    "model_OPT = KerasRegressor(build_fn=create_my_model,\n",
    "                           epochs=50,\n",
    "                           batch_size=40\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "243/243 [==============================] - 0s 562us/step - loss: 1.1272 - mse: 2.0817\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 0s 534us/step - loss: 0.3698 - mse: 0.3483\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 0s 575us/step - loss: 0.1149 - mse: 0.0314\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 0s 542us/step - loss: 0.0547 - mse: 0.0058\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 0s 550us/step - loss: 0.0479 - mse: 0.0044\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 0s 562us/step - loss: 0.0448 - mse: 0.0038\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0431 - mse: 0.0035\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0412 - mse: 0.0033\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 0s 538us/step - loss: 0.0404 - mse: 0.0031\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 0s 550us/step - loss: 0.0394 - mse: 0.0030\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 0s 579us/step - loss: 0.0388 - mse: 0.0029\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 0s 542us/step - loss: 0.0377 - mse: 0.0028\n",
      "Epoch 13/50\n",
      "243/243 [==============================] - 0s 546us/step - loss: 0.0369 - mse: 0.0027\n",
      "Epoch 14/50\n",
      "243/243 [==============================] - 0s 534us/step - loss: 0.0374 - mse: 0.0028\n",
      "Epoch 15/50\n",
      "243/243 [==============================] - 0s 566us/step - loss: 0.0364 - mse: 0.0027\n",
      "Epoch 16/50\n",
      "243/243 [==============================] - 0s 529us/step - loss: 0.0361 - mse: 0.0026\n",
      "Epoch 17/50\n",
      "243/243 [==============================] - 0s 534us/step - loss: 0.0359 - mse: 0.0026\n",
      "Epoch 18/50\n",
      "243/243 [==============================] - 0s 767us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 19/50\n",
      "243/243 [==============================] - 0s 677us/step - loss: 0.0357 - mse: 0.0025\n",
      "Epoch 20/50\n",
      "243/243 [==============================] - 0s 583us/step - loss: 0.0357 - mse: 0.0026\n",
      "Epoch 21/50\n",
      "243/243 [==============================] - 0s 558us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 22/50\n",
      "243/243 [==============================] - 0s 587us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 23/50\n",
      "243/243 [==============================] - 0s 583us/step - loss: 0.0352 - mse: 0.0025\n",
      "Epoch 24/50\n",
      "243/243 [==============================] - 0s 562us/step - loss: 0.0358 - mse: 0.0026\n",
      "Epoch 25/50\n",
      "243/243 [==============================] - 0s 776us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 26/50\n",
      "243/243 [==============================] - 0s 624us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 27/50\n",
      "243/243 [==============================] - 0s 558us/step - loss: 0.0350 - mse: 0.0025\n",
      "Epoch 28/50\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0355 - mse: 0.0025\n",
      "Epoch 29/50\n",
      "243/243 [==============================] - 0s 579us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 30/50\n",
      "243/243 [==============================] - 0s 591us/step - loss: 0.0356 - mse: 0.0025\n",
      "Epoch 31/50\n",
      "243/243 [==============================] - 0s 591us/step - loss: 0.0350 - mse: 0.0025\n",
      "Epoch 32/50\n",
      "243/243 [==============================] - 0s 599us/step - loss: 0.0352 - mse: 0.0025\n",
      "Epoch 33/50\n",
      "243/243 [==============================] - 0s 731us/step - loss: 0.0346 - mse: 0.0024\n",
      "Epoch 34/50\n",
      "243/243 [==============================] - 0s 694us/step - loss: 0.0353 - mse: 0.0025\n",
      "Epoch 35/50\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0360 - mse: 0.0026\n",
      "Epoch 36/50\n",
      "243/243 [==============================] - 0s 603us/step - loss: 0.0344 - mse: 0.0024\n",
      "Epoch 37/50\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0351 - mse: 0.0025\n",
      "Epoch 38/50\n",
      "243/243 [==============================] - 0s 579us/step - loss: 0.0349 - mse: 0.0025\n",
      "Epoch 39/50\n",
      "243/243 [==============================] - 0s 587us/step - loss: 0.0354 - mse: 0.0025\n",
      "Epoch 40/50\n",
      "243/243 [==============================] - 0s 583us/step - loss: 0.0357 - mse: 0.0026\n",
      "Epoch 41/50\n",
      "243/243 [==============================] - 0s 755us/step - loss: 0.0348 - mse: 0.0024\n",
      "Epoch 42/50\n",
      "243/243 [==============================] - 0s 726us/step - loss: 0.0348 - mse: 0.0025\n",
      "Epoch 43/50\n",
      "243/243 [==============================] - 0s 735us/step - loss: 0.0346 - mse: 0.0025\n",
      "Epoch 44/50\n",
      "243/243 [==============================] - 0s 669us/step - loss: 0.0346 - mse: 0.0024\n",
      "Epoch 45/50\n",
      "243/243 [==============================] - 0s 566us/step - loss: 0.0350 - mse: 0.0025\n",
      "Epoch 46/50\n",
      "243/243 [==============================] - 0s 521us/step - loss: 0.0346 - mse: 0.0024\n",
      "Epoch 47/50\n",
      "243/243 [==============================] - 0s 513us/step - loss: 0.0347 - mse: 0.0024\n",
      "Epoch 48/50\n",
      "243/243 [==============================] - 0s 505us/step - loss: 0.0344 - mse: 0.0024\n",
      "Epoch 49/50\n",
      "243/243 [==============================] - 0s 509us/step - loss: 0.0343 - mse: 0.0024\n",
      "Epoch 50/50\n",
      "243/243 [==============================] - 0s 525us/step - loss: 0.0349 - mse: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "optimizer = ['SGD','Adadelta', 'RMSprop', 'Adagrad','Adam','Adamax']\n",
    "parameter_grid = dict(optimizer=optimizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_OPT, param_grid=parameter_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.036512 using {'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 64, 'step': 4, 'sampling': None}\n",
      "D_rate_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 1.0, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.15, 'conditions': [], 'values': [0.15, 0.1, 0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=2,\n",
    "                                            max_value=64,\n",
    "                                            step=4,            \n",
    "#                                             sampling=\"log\"\n",
    "                                           ),\n",
    "                                            activation= 'relu'\n",
    "                              ))\n",
    "#         for i in [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] \n",
    "        model.add(layers.Dropout(rate=hp.Float('D_rate_'+ str(i),\n",
    "                                              min_value=0.0,\n",
    "                                              max_value=1.0,\n",
    "                                              step=0.1\n",
    "                                              #sampling=\"log\"\n",
    "                                              ),       \n",
    "                                ))\n",
    "\n",
    "    model.add(layers.Dense(1,\n",
    "#                            activation='linear'\n",
    "                          ))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate', [0.15, 0.1, 1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=  'val_loss',   #   'val_mean_absolute_error', #(['loss', 'mse', 'val_loss', 'val_mse']\n",
    "    max_trials=10,\n",
    "    executions_per_trial=7,\n",
    "    directory='Test_weights2',\n",
    "    project_name='ANNTuning2')\n",
    "\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-52c5a44a2d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m tuner.search(train_input, train_target,\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#              epochs=35,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tuner' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "    \n",
    "tuner.search(train_input, train_target,\n",
    "             epochs=35,\n",
    "             validation_data=(test_input, test_target),            \n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Test_weights2\\ANNTuning2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 58\n",
      "D_rate_0: 0.5\n",
      "learning_rate: 0.001\n",
      "units_1: 38\n",
      "D_rate_1: 0.4\n",
      "units_2: 22\n",
      "D_rate_2: 0.4\n",
      "units_3: 54\n",
      "D_rate_3: 0.2\n",
      "units_4: 6\n",
      "D_rate_4: 0.9\n",
      "units_5: 34\n",
      "D_rate_5: 0.1\n",
      "units_6: 22\n",
      "D_rate_6: 0.9\n",
      "Score: 0.04048472908990724\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 6\n",
      "D_rate_0: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 30\n",
      "D_rate_1: 0.5\n",
      "units_2: 10\n",
      "D_rate_2: 0.30000000000000004\n",
      "units_3: 42\n",
      "D_rate_3: 0.30000000000000004\n",
      "units_4: 58\n",
      "D_rate_4: 0.5\n",
      "units_5: 30\n",
      "D_rate_5: 0.5\n",
      "units_6: 46\n",
      "D_rate_6: 0.9\n",
      "Score: 0.05250928071992738\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 34\n",
      "D_rate_0: 0.2\n",
      "learning_rate: 0.1\n",
      "units_1: 46\n",
      "D_rate_1: 0.30000000000000004\n",
      "units_2: 2\n",
      "D_rate_2: 0.1\n",
      "units_3: 46\n",
      "D_rate_3: 0.7000000000000001\n",
      "units_4: 62\n",
      "D_rate_4: 0.30000000000000004\n",
      "units_5: 26\n",
      "D_rate_5: 0.1\n",
      "units_6: 58\n",
      "D_rate_6: 0.5\n",
      "Score: 0.05286812888724463\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 62\n",
      "D_rate_0: 0.5\n",
      "learning_rate: 0.001\n",
      "units_1: 30\n",
      "D_rate_1: 0.30000000000000004\n",
      "units_2: 14\n",
      "D_rate_2: 0.8\n",
      "units_3: 42\n",
      "D_rate_3: 0.6000000000000001\n",
      "units_4: 18\n",
      "D_rate_4: 0.6000000000000001\n",
      "units_5: 62\n",
      "D_rate_5: 0.4\n",
      "units_6: 38\n",
      "D_rate_6: 0.8\n",
      "units_7: 62\n",
      "D_rate_7: 0.9\n",
      "Score: 0.06273139853562627\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 42\n",
      "D_rate_0: 0.6000000000000001\n",
      "learning_rate: 0.001\n",
      "units_1: 54\n",
      "D_rate_1: 0.6000000000000001\n",
      "units_2: 2\n",
      "D_rate_2: 0.4\n",
      "units_3: 46\n",
      "D_rate_3: 0.9\n",
      "units_4: 30\n",
      "D_rate_4: 0.2\n",
      "units_5: 34\n",
      "D_rate_5: 0.7000000000000001\n",
      "units_6: 46\n",
      "D_rate_6: 0.8\n",
      "Score: 0.06394560581871442\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 38\n",
      "D_rate_0: 0.1\n",
      "learning_rate: 0.001\n",
      "units_1: 10\n",
      "D_rate_1: 0.8\n",
      "units_2: 14\n",
      "D_rate_2: 0.8\n",
      "units_3: 50\n",
      "D_rate_3: 0.0\n",
      "units_4: 22\n",
      "D_rate_4: 0.5\n",
      "units_5: 46\n",
      "D_rate_5: 0.5\n",
      "units_6: 2\n",
      "D_rate_6: 0.5\n",
      "units_7: 14\n",
      "D_rate_7: 0.6000000000000001\n",
      "Score: 0.07275282059397016\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 7\n",
      "units_0: 18\n",
      "D_rate_0: 0.5\n",
      "learning_rate: 0.1\n",
      "units_1: 2\n",
      "D_rate_1: 0.0\n",
      "units_2: 2\n",
      "D_rate_2: 0.0\n",
      "units_3: 2\n",
      "D_rate_3: 0.0\n",
      "units_4: 2\n",
      "D_rate_4: 0.0\n",
      "units_5: 2\n",
      "D_rate_5: 0.0\n",
      "units_6: 2\n",
      "D_rate_6: 0.0\n",
      "Score: 0.08004962972232274\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 18\n",
      "D_rate_0: 0.8\n",
      "learning_rate: 0.15\n",
      "units_1: 54\n",
      "D_rate_1: 0.8\n",
      "units_2: 50\n",
      "D_rate_2: 0.4\n",
      "units_3: 6\n",
      "D_rate_3: 0.30000000000000004\n",
      "units_4: 58\n",
      "D_rate_4: 0.1\n",
      "units_5: 54\n",
      "D_rate_5: 0.30000000000000004\n",
      "units_6: 58\n",
      "D_rate_6: 0.6000000000000001\n",
      "units_7: 2\n",
      "D_rate_7: 0.0\n",
      "Score: 0.08521907776594162\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 2\n",
      "D_rate_0: 0.7000000000000001\n",
      "learning_rate: 0.0001\n",
      "units_1: 50\n",
      "D_rate_1: 0.1\n",
      "units_2: 14\n",
      "D_rate_2: 0.1\n",
      "units_3: 22\n",
      "D_rate_3: 0.30000000000000004\n",
      "units_4: 14\n",
      "D_rate_4: 0.4\n",
      "units_5: 34\n",
      "D_rate_5: 0.9\n",
      "units_6: 46\n",
      "D_rate_6: 0.5\n",
      "units_7: 18\n",
      "D_rate_7: 0.5\n",
      "Score: 0.2103550455399922\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 18\n",
      "D_rate_0: 0.6000000000000001\n",
      "learning_rate: 0.0001\n",
      "units_1: 58\n",
      "D_rate_1: 0.1\n",
      "units_2: 62\n",
      "D_rate_2: 0.0\n",
      "units_3: 30\n",
      "D_rate_3: 0.2\n",
      "units_4: 62\n",
      "D_rate_4: 0.9\n",
      "units_5: 34\n",
      "D_rate_5: 0.9\n",
      "units_6: 2\n",
      "D_rate_6: 0.6000000000000001\n",
      "Score: 0.42699864506721497\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 58)                232       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 58)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 38)                2242      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 22)                858       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 54)                1242      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 54)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6)                 330       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 34)                238       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 22)                770       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 5,935\n",
      "Trainable params: 5,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# A function to hold preprocessor, layers, model and compiler \n",
    "def FFBackProp(inputs, output):\n",
    "\n",
    "    \n",
    "    model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(58,activation=\"relu\"\n",
    "                          , input_shape=(3,), \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "        \n",
    "    tf.keras.layers.Dense(38,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "    tf.keras.layers.Dense(22,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    tf.keras.layers.Dense(54,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(6,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.9),\n",
    "    tf.keras.layers.Dense(34,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "            tf.keras.layers.Dense(22,activation=\"relu\", \n",
    "#                           kernel_regularizer=\"l2\"\n",
    "                         ),\n",
    "    tf.keras.layers.Dropout(0.9),\n",
    "\n",
    "    \n",
    "        #output layer\n",
    "    tf.keras.layers.Dense(1),\n",
    "  ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     compile the model\n",
    "    model1.compile(optimizer='adam',\n",
    "                loss='mean_absolute_error', #(from_logits=True),\n",
    "                metrics=[\"mse\"],\n",
    "#                 learning_rate=0.001\n",
    "               )\n",
    "    \n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "myFFBP= FFBackProp(train_input,train_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "myFFBPtraining = myFFBP.fit(\n",
    "    train_input, train_target,\n",
    "    # Calculate validation results on 30% of the training data\n",
    "    validation_split=0.3,\n",
    "     # suppress logging\n",
    "    verbose=0,\n",
    "#     epochs=100,\n",
    "    \n",
    "\n",
    "    #early stopping\n",
    "    #an attempt to prevent overfitting\n",
    "    #the fuction to stop the trianing by tracking the validation loss\n",
    "    callbacks= keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "    \n",
    "    #to store callbacks in logs\n",
    "#     callbacks =[tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (mse): 1.1927307844161987\n",
      "Test mae: 1.4349908828735352\n"
     ]
    }
   ],
   "source": [
    "# collect the results in a set\n",
    "test_results={}\n",
    "# test_results['FFBP']\n",
    "\n",
    "test_mse, test_mae= myFFBP.evaluate(test_input, test_target, verbose=0, )\n",
    "print('Test loss (mse):', test_mse)\n",
    "print('Test mae:', test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predicted = myFFBP.predict(test_input) #.flatten() ##Flattening converts multidimensional lists into one-dimensional lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: -114.88256899352649\n",
      "mse: 1.4349908106141642\n",
      "rmse: 1.1979110194894127\n",
      "mae: 1.1927310191023521\n"
     ]
    }
   ],
   "source": [
    "# using sklearn\n",
    "print(\"r2 score: {}\".format(metrics.r2_score(test_target,predicted)))\n",
    "print(\"mse: {}\".format(metrics.mean_squared_error(test_target, predicted)))\n",
    "print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error(test_target, predicted))))\n",
    "print(\"mae: {}\".format(metrics.mean_absolute_error(test_target, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on different wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: -33.72337042959991\n",
      "mse: 0.8622181184556674\n",
      "rmse: 0.9285570087268027\n",
      "mae: 0.543222936576818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feat_extracts well3\n",
    "def predictme(well_name):\n",
    "    xlsx_2 = pd.ExcelFile(well_name)\n",
    "    df_2 = pd.read_excel(xlsx_2, 'PCAs')\n",
    "    dataset_pca_2= df_2.copy()\n",
    "\n",
    "\n",
    "    # dataset_pca.pop('PC3')\n",
    "    dataset_pca_2.pop('index')\n",
    "\n",
    "    dataset_pca_2\n",
    "\n",
    "\n",
    "    xlsx_2y = pd.ExcelFile(well_name)\n",
    "    df_2y = pd.read_excel(xlsx_2y, 'target')\n",
    "    pca_target_2y= df_2y.copy()\n",
    "\n",
    "    # pca_target_2y.pop('RHOB')\n",
    "    pca_target_2y\n",
    "\n",
    "\n",
    "\n",
    "    predicted_2y = myFFBP.predict(dataset_pca_2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(pca_target_2y, predicted_2y, alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('True Values')\n",
    "    ax.set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "    print(\"r2 score: {}\".format(metrics.r2_score(pca_target_2y, predicted_2y)))\n",
    "    print(\"mse: {}\".format(metrics.mean_squared_error(pca_target_2y, predicted_2y)))\n",
    "    print(\"rmse: {}\".format(np.sqrt(metrics.mean_squared_error(pca_target_2y, predicted_2y))))\n",
    "    print(\"mae: {}\".format(metrics.mean_absolute_error(pca_target_2y, predicted_2y)))\n",
    "    \n",
    "    return \n",
    "\n",
    "predictme(\"Feat_extracts well4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
